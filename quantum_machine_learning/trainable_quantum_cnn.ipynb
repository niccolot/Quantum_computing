{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "n_qbits = 9\n",
    "num_train_images = 1000\n",
    "\n",
    "quantum_device = qml.device(\"default.qubit\", wires=n_qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PLOTTING FUNCTIONS\n",
    "\"\"\"\n",
    "\n",
    "def plot_loss_metric(loss, val_loss, metric, val_metric, metric_name='accuracy'):\n",
    "\n",
    "    epochs_range = range(len(loss))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if metric_name == 'accuracy':\n",
    "        plt.plot(epochs_range, metric, label='Training Accuracy')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "    elif metric_name == 'recall':\n",
    "        plt.plot(epochs_range, metric, label='Training Recall')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Recall')\n",
    "        plt.title('Training and Validation Recall')\n",
    "    elif metric_name == 'precision':\n",
    "        plt.plot(epochs_range, metric, label='Training Precision')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Precision')\n",
    "        plt.title('Training and Validation Precision')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(dataset, labels, val_split=0.25):\n",
    "\n",
    "    dataset = dataset/255.\n",
    "    dataset = np.expand_dims(dataset, axis=3)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset, labels, test_size=0.25, random_state=25)\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "    y_val = keras.utils.to_categorical(y_val)\n",
    "\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical custom conv, problems with the outputs being (28,28,1) and not (None, 28, 28, 1) as usual shown in model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input, weight):\n",
    "\n",
    "    output = tf.math.multiply(input, weight)\n",
    "    output = tf.math.reduce_mean(output)\n",
    "        \n",
    "    return tf.keras.activations.relu(output)\n",
    "\n",
    "\n",
    "class CustomConv(keras.layers.Layer):\n",
    "    def __init__(self, dim_kernel=3, filters=8):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim_kernel = dim_kernel\n",
    "        self.filters = filters\n",
    "        self.w = self.add_weight(\n",
    "            shape = (self.dim_kernel, self.dim_kernel, self.filters),\n",
    "            initializer = 'random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.rows = input_shape[0]\n",
    "        self.cols = input_shape[1]\n",
    "        self.channels_in = input_shape[2]\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        output_tensor = []\n",
    "        padded_image = tf.pad(inputs, paddings=[(1,1), (1,1), (0,0)])\n",
    "\n",
    "        for filter in range(self.filters):\n",
    "            for i in range(self.rows):\n",
    "                for j in range(self.cols):\n",
    "                    for k in range(self.channels_in):\n",
    "\n",
    "                        input_tensor = padded_image[i:i+self.dim_kernel, j:j+self.dim_kernel, k]\n",
    "                        output_tensor.append(conv(input_tensor, self.w[:,:,filter]))\n",
    "        \n",
    "        output_tensor = tf.stack(output_tensor)\n",
    "        output_tensor = tf.reshape(output_tensor, shape=(1,self.rows, self.cols, self.filters))\n",
    "\n",
    "        return output_tensor\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_1\" (type Reshape).\n\nTried to convert 'shape' to a tensor and failed. Error: None values not supported.\n\nCall arguments received by layer \"reshape_1\" (type Reshape):\n  • inputs=tf.Tensor(shape=(1, 28, 28, 16), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nico_\\OneDrive\\Documenti\\Programmi\\Quantum_computing\\quantum_machine_learning\\trainable_quantum_cnn.ipynb Cella 5\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m optimizer \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     loss\u001b[39m=\u001b[39mloss,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     optimizer\u001b[39m=\u001b[39moptimizer,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m model\u001b[39m.\u001b[39;49mbuild(input_shape\u001b[39m=\u001b[39;49m(\u001b[39m28\u001b[39;49m,\u001b[39m28\u001b[39;49m,\u001b[39m1\u001b[39;49m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\sequential.py:349\u001b[0m, in \u001b[0;36mSequential.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m     input_shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(input_shape)\n\u001b[0;32m    348\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_input_shape \u001b[39m=\u001b[39m input_shape\n\u001b[1;32m--> 349\u001b[0m     \u001b[39msuper\u001b[39;49m(Sequential, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mbuild(input_shape)\n\u001b[0;32m    350\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:449\u001b[0m, in \u001b[0;36mModel.build\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    445\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    446\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mYou can only call `build()` on a model if its `call()` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    447\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mmethod accepts an `inputs` argument.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    448\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 449\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(x, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mInvalidArgumentError, \u001b[39mTypeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mYou cannot build your model by calling `build` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    452\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mif your layers do not support float type inputs. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    453\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mInstead, in order to instantiate and build your \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    454\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mmodel, call your model on real tensor data (of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    455\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mthe correct dtype).\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mThe actual error from \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    456\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`call` is: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\sequential.py:388\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m argspec:\n\u001b[0;32m    386\u001b[0m   kwargs[\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m training\n\u001b[1;32m--> 388\u001b[0m outputs \u001b[39m=\u001b[39m layer(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    391\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(SINGLE_LAYER_OUTPUT_ERROR_MSG)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:573\u001b[0m, in \u001b[0;36m_ExtractInputsAndAttrs\u001b[1;34m(op_type_name, op_def, allowed_list_attr_map, keywords, default_type_attr_map, attrs, inputs, input_types)\u001b[0m\n\u001b[0;32m    570\u001b[0m   observed \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[0;32m    571\u001b[0m       values, as_ref\u001b[39m=\u001b[39minput_arg\u001b[39m.\u001b[39mis_ref)\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mname\n\u001b[0;32m    572\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 573\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTried to convert \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00minput_name\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to a tensor and failed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError: \u001b[39m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m prefix \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m Op has type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m that does not match\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    577\u001b[0m           (input_name, op_type_name, observed))\n\u001b[0;32m    578\u001b[0m \u001b[39mif\u001b[39;00m input_arg\u001b[39m.\u001b[39mtype \u001b[39m!=\u001b[39m types_pb2\u001b[39m.\u001b[39mDT_INVALID:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_1\" (type Reshape).\n\nTried to convert 'shape' to a tensor and failed. Error: None values not supported.\n\nCall arguments received by layer \"reshape_1\" (type Reshape):\n  • inputs=tf.Tensor(shape=(1, 28, 28, 16), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    CustomConv(),\n",
    "    layers.Conv2D(16, 3, trainable=False, padding='same'),\n",
    "    layers.Reshape((None,28,28,16))#reshaping with 'None' as a dimension doesn't work either\n",
    "])\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.build(input_shape=(28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum custom conv based on the previous, the only difference is the function that outputs the feature maps, a \n",
    "convolution for the former cells and a quantum circuit for the subsequent cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(quantum_device, interface=\"tf\")\n",
    "def q_circuit(input, weights):\n",
    "            \n",
    "    features = tf.squeeze(input)\n",
    "    num_qbits = len(features)\n",
    "\n",
    "    qml.AngleEmbedding(features=features, wires=range(n_qbits), rotation='X')\n",
    "    qml.BasicEntanglerLayers(weights=weights, wires=range(n_qbits))\n",
    "            \n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_qbits)]\n",
    "\n",
    "\n",
    "class QuantumConvolution(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, q_filters=16, dim_q_kernel=3, circuit_layers=2):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim_q_kernel = dim_q_kernel\n",
    "        self.q_filters = q_filters\n",
    "        self.circuit_layers = circuit_layers\n",
    "        self.w = self.add_weight(\n",
    "            shape = (self.circuit_layers, (self.dim_q_kernel)**2, self.q_filters),\n",
    "            initializer = 'random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.rows = input_shape[0]\n",
    "        self.cols = input_shape[1]\n",
    "        self.channels_in = input_shape[2]\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        output_tensor = []\n",
    "        padded_image = tf.pad(inputs, paddings=[(1,1), (1,1), (0,0)])\n",
    "\n",
    "        for filter in range(self.q_filters):\n",
    "            for i in range(self.rows):\n",
    "                for j in range(self.cols):\n",
    "                    for k in range(self.channels_in):\n",
    "\n",
    "                        input_tensor = padded_image[i:i+self.dim_q_kernel, j:j+self.dim_q_kernel, k]\n",
    "                        measurements = q_circuit(input_tensor, self.w[:,:,filter])\n",
    "                        measurements = tf.math.reduce_mean(measurements)\n",
    "                        measurements = tf.keras.activations.relu(measurements)\n",
    "                        output_tensor.append(measurements)\n",
    "        \n",
    "        output_tensor = tf.stack(output_tensor)\n",
    "        output_tensor = tf.reshape(output_tensor, shape=(self.rows, self.cols, self.q_filters))\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    QuantumConvolution(),\n",
    "    #layers.Conv2D(16,3, trainable=False),\n",
    "])\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.build(input_shape=(28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to put a quantum layer as a dense layer at the end of the classical model, used the pennylan tool\n",
    "for converting a quantum function to a keras layer (https://pennylane.ai/qml/demos/tutorial_qnn_module_tf.html)\n",
    "it presents a bug as it states that the weights of the quantum circuit are 'unused' as one can see\n",
    "in model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(quantum_device)\n",
    "def quantum_convolution(\n",
    "    inputs,\n",
    "    weights):\n",
    "\n",
    "    features = np.ravel(inputs)\n",
    "    qml.AngleEmbedding(features, wires=range(n_qbits), rotation='X')\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qbits))\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_qbits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_shapes = {\"weights\": (2, 9)}\n",
    "\n",
    "qlayer = qml.qnn.KerasLayer(quantum_convolution, weight_shapes, output_dim=n_qbits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 1)         10        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 1)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 1)         10        \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 1)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 1)           10        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 1)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 9)                 0 (unused)\n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130\n",
      "Trainable params: 0\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(1,3, activation='relu', padding='same', trainable=False, input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(1,3, activation='relu', padding='same', trainable=False),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(1,3, activation='relu', padding='same', trainable=False),\n",
    "    layers.MaxPooling2D(),\n",
    "    qlayer,\n",
    "    layers.Dense(10, activation='softmax', trainable=False)\n",
    "])\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images[:num_train_images]\n",
    "train_labels = train_labels[:num_train_images]\n",
    "\n",
    "x_train, x_val, y_train, y_val = prep_dataset(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the 'unused' next to the quantum circuit layer in the previous model.summry() the weights seems to enter in the\n",
    "optimization routine as all the other layers are set to 'trainable = False' and the loss stil goes down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/47 [==============>...............] - ETA: 1:43 - loss: 2.3220 - accuracy: 0.0812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m<frozen importlib._bootstrap>:166\u001b[0m, in \u001b[0;36m_get_module_lock\u001b[1;34m(name)\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nico_\\OneDrive\\Documenti\\Programmi\\Quantum_computing\\quantum_machine_learning\\trainable_quantum_cnn.ipynb Cella 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     x \u001b[39m=\u001b[39;49m x_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     y \u001b[39m=\u001b[39;49m y_train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     validation_data\u001b[39m=\u001b[39;49m(x_val, y_val),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nico_/OneDrive/Documenti/Programmi/Quantum_computing/quantum_machine_learning/trainable_quantum_cnn.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1051\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_function\u001b[39m(iterator):\n\u001b[0;32m   1050\u001b[0m   \u001b[39m\"\"\"Runs a training execution with a single step.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1051\u001b[0m   \u001b[39mreturn\u001b[39;00m step_function(\u001b[39mself\u001b[39;49m, iterator)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1040\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function\u001b[1;34m(model, iterator)\u001b[0m\n\u001b[0;32m   1037\u001b[0m   run_step \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mfunction(\n\u001b[0;32m   1038\u001b[0m       run_step, jit_compile\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, reduce_retracing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   1039\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(iterator)\n\u001b[1;32m-> 1040\u001b[0m outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdistribute_strategy\u001b[39m.\u001b[39;49mrun(run_step, args\u001b[39m=\u001b[39;49m(data,))\n\u001b[0;32m   1041\u001b[0m outputs \u001b[39m=\u001b[39m reduce_per_replica(\n\u001b[0;32m   1042\u001b[0m     outputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy, reduction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfirst\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1043\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1312\u001b[0m, in \u001b[0;36mStrategyBase.run\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   1307\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope():\n\u001b[0;32m   1308\u001b[0m   \u001b[39m# tf.distribute supports Eager functions, so AutoGraph should not be\u001b[39;00m\n\u001b[0;32m   1309\u001b[0m   \u001b[39m# applied when the caller is also in Eager mode.\u001b[39;00m\n\u001b[0;32m   1310\u001b[0m   fn \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39mtf_convert(\n\u001b[0;32m   1311\u001b[0m       fn, autograph_ctx\u001b[39m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m-> 1312\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_extended\u001b[39m.\u001b[39;49mcall_for_each_replica(fn, args\u001b[39m=\u001b[39;49margs, kwargs\u001b[39m=\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2888\u001b[0m, in \u001b[0;36mStrategyExtendedV1.call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   2886\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m   2887\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy()\u001b[39m.\u001b[39mscope():\n\u001b[1;32m-> 2888\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_for_each_replica(fn, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3689\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._call_for_each_replica\u001b[1;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[0;32m   3687\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_for_each_replica\u001b[39m(\u001b[39mself\u001b[39m, fn, args, kwargs):\n\u001b[0;32m   3688\u001b[0m   \u001b[39mwith\u001b[39;00m ReplicaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_container_strategy(), replica_id_in_sync_group\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m):\n\u001b[1;32m-> 3689\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:595\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    594\u001b[0m   \u001b[39mwith\u001b[39;00m ag_ctx\u001b[39m.\u001b[39mControlStatusCtx(status\u001b[39m=\u001b[39mag_ctx\u001b[39m.\u001b[39mStatus\u001b[39m.\u001b[39mUNSPECIFIED):\n\u001b[1;32m--> 595\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:1030\u001b[0m, in \u001b[0;36mModel.make_train_function.<locals>.step_function.<locals>.run_step\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1029\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_step\u001b[39m(data):\n\u001b[1;32m-> 1030\u001b[0m   outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mtrain_step(data)\n\u001b[0;32m   1031\u001b[0m   \u001b[39m# Ensure counter is updated only if `train_step` succeeds.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m   \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mcontrol_dependencies(_minimum_control_deps(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:889\u001b[0m, in \u001b[0;36mModel.train_step\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[39m# Run forward pass.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mGradientTape() \u001b[39mas\u001b[39;00m tape:\n\u001b[1;32m--> 889\u001b[0m   y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(x, training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    890\u001b[0m   loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_loss(x, y, y_pred, sample_weight)\n\u001b[0;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_target_and_loss(y, loss)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\training.py:490\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(inputs, \u001b[39m*\u001b[39mcopied_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    488\u001b[0m   layout_map_lib\u001b[39m.\u001b[39m_map_subclass_model_variable(\u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout_map)\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\sequential.py:374\u001b[0m, in \u001b[0;36mSequential.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    372\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt:\n\u001b[0;32m    373\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_graph_network(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)\n\u001b[1;32m--> 374\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(Sequential, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mcall(inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[0;32m    376\u001b[0m outputs \u001b[39m=\u001b[39m inputs  \u001b[39m# handle the corner case where self.layers is empty\u001b[39;00m\n\u001b[0;32m    377\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m    378\u001b[0m   \u001b[39m# During each iteration, `inputs` are the inputs to `layer`, and `outputs`\u001b[39;00m\n\u001b[0;32m    379\u001b[0m   \u001b[39m# are the outputs of `layer` applied to `inputs`. At the end of each\u001b[39;00m\n\u001b[0;32m    380\u001b[0m   \u001b[39m# iteration `inputs` is set to `outputs` to prepare for the next layer.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py:458\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, inputs, training\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    441\u001b[0m   \u001b[39m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \n\u001b[0;32m    443\u001b[0m \u001b[39m  In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[39m      a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 458\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_internal_graph(\n\u001b[0;32m    459\u001b[0m       inputs, training\u001b[39m=\u001b[39;49mtraining, mask\u001b[39m=\u001b[39;49mmask)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\functional.py:596\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    593\u001b[0m   \u001b[39mcontinue\u001b[39;00m  \u001b[39m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    595\u001b[0m args, kwargs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 596\u001b[0m outputs \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlayer(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    598\u001b[0m \u001b[39m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    599\u001b[0m \u001b[39mfor\u001b[39;00m x_id, y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(node\u001b[39m.\u001b[39mflat_output_ids, tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(outputs)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\engine\\base_layer.py:1014\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m   inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1012\u001b[0m \u001b[39mwith\u001b[39;00m autocast_variable\u001b[39m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1013\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compute_dtype_object):\n\u001b[1;32m-> 1014\u001b[0m   outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1016\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1017\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras\\utils\\traceback_utils.py:92\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m bound_signature \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 92\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     93\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     94\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39m_keras_call_info_injected\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     95\u001b[0m     \u001b[39m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\qnn\\keras.py:302\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    300\u001b[0m     reconstructor \u001b[39m=\u001b[39m []\n\u001b[0;32m    301\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39munstack(inputs):\n\u001b[1;32m--> 302\u001b[0m         reconstructor\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(x))\n\u001b[0;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mstack(reconstructor)\n\u001b[0;32m    305\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_evaluate_qnode(inputs)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\qnn\\keras.py:305\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    302\u001b[0m         reconstructor\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcall(x))\n\u001b[0;32m    303\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mstack(reconstructor)\n\u001b[1;32m--> 305\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_qnode(inputs)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\qnn\\keras.py:320\u001b[0m, in \u001b[0;36mKerasLayer._evaluate_qnode\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[39m\"\"\"Evaluates a QNode for a single input datapoint.\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \n\u001b[0;32m    310\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39m    tensor: output datapoint\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    316\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    317\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_arg: x},\n\u001b[0;32m    318\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: \u001b[39m1.0\u001b[39m \u001b[39m*\u001b[39m w \u001b[39mfor\u001b[39;00m k, w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqnode_weights\u001b[39m.\u001b[39mitems()},\n\u001b[0;32m    319\u001b[0m }\n\u001b[1;32m--> 320\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\qnode.py:661\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    657\u001b[0m             res \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(res)\n\u001b[0;32m    659\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[1;32m--> 661\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    662\u001b[0m     [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtape],\n\u001b[0;32m    663\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[0;32m    664\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[0;32m    665\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[0;32m    666\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[0;32m    667\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[0;32m    668\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[0;32m    669\u001b[0m )\n\u001b[0;32m    671\u001b[0m \u001b[39mif\u001b[39;00m autograd\u001b[39m.\u001b[39misinstance(res, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(res) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    672\u001b[0m     \u001b[39m# If a device batch transform was applied, we need to 'unpack'\u001b[39;00m\n\u001b[0;32m    673\u001b[0m     \u001b[39m# the returned tuple/list to a float.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[39m# TODO: find a more explicit way of determining that a batch transform\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[39m# was applied.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m     res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\interfaces\\execution.py:370\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, mode, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[0;32m    366\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_fn(res)\n\u001b[0;32m    368\u001b[0m \u001b[39mif\u001b[39;00m gradient_fn \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbackprop\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m interface \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m     \u001b[39mreturn\u001b[39;00m batch_fn(\n\u001b[1;32m--> 370\u001b[0m         qml\u001b[39m.\u001b[39;49minterfaces\u001b[39m.\u001b[39;49mcache_execute(\n\u001b[0;32m    371\u001b[0m             batch_execute, cache, return_tuple\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, expand_fn\u001b[39m=\u001b[39;49mexpand_fn\n\u001b[0;32m    372\u001b[0m         )(tapes)\n\u001b[0;32m    373\u001b[0m     )\n\u001b[0;32m    375\u001b[0m \u001b[39m# the default execution function is batch_execute\u001b[39;00m\n\u001b[0;32m    376\u001b[0m execute_fn \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39minterfaces\u001b[39m.\u001b[39mcache_execute(batch_execute, cache, expand_fn\u001b[39m=\u001b[39mexpand_fn)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\interfaces\\execution.py:197\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[0;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m     res \u001b[39m=\u001b[39m fn(execution_tapes\u001b[39m.\u001b[39;49mvalues(), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    199\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[0;32m    201\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\interfaces\\execution.py:122\u001b[0m, in \u001b[0;36mcache_execute.<locals>.fn\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfn\u001b[39m(tapes, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):  \u001b[39m# pylint: disable=function-redefined\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     tapes \u001b[39m=\u001b[39m [expand_fn(tape) \u001b[39mfor\u001b[39;00m tape \u001b[39min\u001b[39;00m tapes]\n\u001b[1;32m--> 122\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn(tapes, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[1;32m---> 75\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\_qubit_device.py:586\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[1;34m(self, circuits)\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[0;32m    585\u001b[0m     \u001b[39m# TODO: Insert control on value here\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(circuit)\n\u001b[0;32m    587\u001b[0m     results\u001b[39m.\u001b[39mappend(res)\n\u001b[0;32m    589\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mactive:\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\_qubit_device.py:315\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[1;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_validity(circuit\u001b[39m.\u001b[39moperations, circuit\u001b[39m.\u001b[39mobservables)\n\u001b[0;32m    314\u001b[0m \u001b[39m# apply all circuit operations\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(circuit\u001b[39m.\u001b[39;49moperations, rotations\u001b[39m=\u001b[39;49mcircuit\u001b[39m.\u001b[39;49mdiagonalizing_gates, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    317\u001b[0m \u001b[39m# generate computational basis samples\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m circuit\u001b[39m.\u001b[39mis_sampled:\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:257\u001b[0m, in \u001b[0;36mDefaultQubit.apply\u001b[1;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debugger\u001b[39m.\u001b[39msnapshots[\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debugger\u001b[39m.\u001b[39msnapshots)] \u001b[39m=\u001b[39m state_vector\n\u001b[0;32m    256\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 257\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_operation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_state, operation)\n\u001b[0;32m    259\u001b[0m \u001b[39m# store the pre-rotated state\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_rotated_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:285\u001b[0m, in \u001b[0;36mDefaultQubit._apply_operation\u001b[1;34m(self, state, operation)\u001b[0m\n\u001b[0;32m    282\u001b[0m     axes \u001b[39m=\u001b[39m [ax \u001b[39m+\u001b[39m shift \u001b[39mfor\u001b[39;00m ax \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwires\u001b[39m.\u001b[39mindices(wires)]\n\u001b[0;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_ops[operation\u001b[39m.\u001b[39mbase_name](state, axes, inverse\u001b[39m=\u001b[39moperation\u001b[39m.\u001b[39minverse)\n\u001b[1;32m--> 285\u001b[0m matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_asarray(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_unitary_matrix(operation), dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mC_DTYPE)\n\u001b[0;32m    287\u001b[0m \u001b[39mif\u001b[39;00m operation \u001b[39min\u001b[39;00m diagonal_in_z_basis:\n\u001b[0;32m    288\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_diagonal_unitary(state, matrix, wires)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\devices\\default_qubit.py:619\u001b[0m, in \u001b[0;36mDefaultQubit._get_unitary_matrix\u001b[1;34m(self, unitary)\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[39mif\u001b[39;00m unitary \u001b[39min\u001b[39;00m diagonal_in_z_basis:\n\u001b[0;32m    617\u001b[0m     \u001b[39mreturn\u001b[39;00m unitary\u001b[39m.\u001b[39meigvals()\n\u001b[1;32m--> 619\u001b[0m \u001b[39mreturn\u001b[39;00m unitary\u001b[39m.\u001b[39;49mmatrix()\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\operation.py:1391\u001b[0m, in \u001b[0;36mOperation.matrix\u001b[1;34m(self, wire_order)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmatrix\u001b[39m(\u001b[39mself\u001b[39m, wire_order\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> 1391\u001b[0m     canonical_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompute_matrix(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparameters, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhyperparameters)\n\u001b[0;32m   1393\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse:\n\u001b[0;32m   1394\u001b[0m         canonical_matrix \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mconj(qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mmoveaxis(canonical_matrix, \u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\ops\\qubit\\parametric_ops.py:118\u001b[0m, in \u001b[0;36mRX.compute_matrix\u001b[1;34m(theta)\u001b[0m\n\u001b[0;32m    116\u001b[0m c \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39m0\u001b[39mj) \u001b[39m*\u001b[39m c\n\u001b[0;32m    117\u001b[0m js \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39mj \u001b[39m*\u001b[39m s\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mstack([stack_last([c, js]), stack_last([js, c])], axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:207\u001b[0m, in \u001b[0;36mmulti_dispatch.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m interface \u001b[39m=\u001b[39m interface \u001b[39mor\u001b[39;00m _multi_dispatch(dispatch_args)\n\u001b[0;32m    205\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlike\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m interface\n\u001b[1;32m--> 207\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\math\\multi_dispatch.py:539\u001b[0m, in \u001b[0;36mstack\u001b[1;34m(values, axis, like)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[39m@multi_dispatch\u001b[39m(argnum\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m], tensor_list\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m])\n\u001b[0;32m    510\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstack\u001b[39m(values, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, like\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    511\u001b[0m     \u001b[39m\"\"\"Stack a sequence of tensors along the specified axis.\u001b[39;00m\n\u001b[0;32m    512\u001b[0m \n\u001b[0;32m    513\u001b[0m \u001b[39m    .. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[39m           [5.00e+00, 8.00e+00, 1.01e+02]], dtype=float32)>\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 539\u001b[0m     values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mcoerce(values, like\u001b[39m=\u001b[39;49mlike)\n\u001b[0;32m    540\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mstack(values, axis\u001b[39m=\u001b[39maxis, like\u001b[39m=\u001b[39mlike)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\autoray\\autoray.py:85\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     83\u001b[0m     backend \u001b[39m=\u001b[39m infer_backend(like)\n\u001b[1;32m---> 85\u001b[0m \u001b[39mreturn\u001b[39;00m get_lib_fn(backend, fn)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\math\\single_dispatch.py:280\u001b[0m, in \u001b[0;36m_coerce_types_tf\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_coerce_types_tf\u001b[39m(tensors):\n\u001b[0;32m    278\u001b[0m     \u001b[39m\"\"\"Coerce the dtypes of a list of tensors so that they\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[39m    all share the same dtype, without any reduction in information.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m     tf \u001b[39m=\u001b[39m _i(\u001b[39m\"\u001b[39;49m\u001b[39mtf\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    281\u001b[0m     tensors \u001b[39m=\u001b[39m [tf\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tensors]\n\u001b[0;32m    282\u001b[0m     dtypes \u001b[39m=\u001b[39m {i\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tensors}\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pennylane\\math\\single_dispatch.py:28\u001b[0m, in \u001b[0;36m_i\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39m\"\"\"Convenience function to import PennyLane\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39minterfaces via a string pattern\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mreturn\u001b[39;00m import_module(\u001b[39m\"\u001b[39;49m\u001b[39mtensorflow\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     30\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mqml\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m import_module(\u001b[39m\"\u001b[39m\u001b[39mpennylane\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nico_\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:988\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:148\u001b[0m, in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:167\u001b[0m, in \u001b[0;36m_get_module_lock\u001b[1;34m(name)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f84fa9da9fc9effead0dc3a0ddec46df01cd77a4c130e3b9442917017e134d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
