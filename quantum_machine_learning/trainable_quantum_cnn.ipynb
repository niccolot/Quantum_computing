{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 2\n",
    "n_qbits = 9\n",
    "num_train_images = 10\n",
    "\n",
    "quantum_device = qml.device(\"default.qubit\", wires=n_qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PLOTTING FUNCTIONS\n",
    "\"\"\"\n",
    "\n",
    "def plot_loss_metric(loss, val_loss, metric, val_metric, metric_name='accuracy'):\n",
    "\n",
    "    epochs_range = range(len(loss))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if metric_name == 'accuracy':\n",
    "        plt.plot(epochs_range, metric, label='Training Accuracy')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "    elif metric_name == 'recall':\n",
    "        plt.plot(epochs_range, metric, label='Training Recall')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Recall')\n",
    "        plt.title('Training and Validation Recall')\n",
    "    elif metric_name == 'precision':\n",
    "        plt.plot(epochs_range, metric, label='Training Precision')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Precision')\n",
    "        plt.title('Training and Validation Precision')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataset(dataset, labels, val_split=0.25):\n",
    "\n",
    "    dataset = dataset/255.\n",
    "    dataset = np.expand_dims(dataset, axis=3)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(dataset, labels, test_size=0.25, random_state=25)\n",
    "    y_train = keras.utils.to_categorical(y_train)\n",
    "    y_val = keras.utils.to_categorical(y_val)\n",
    "\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical custom conv, problems with the outputs being (28,28,1) and not (None, 28, 28, 1) as usual shown in model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(input, weight):\n",
    "\n",
    "    output = tf.math.multiply(input, weight)\n",
    "    output = tf.math.reduce_mean(output)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "class CustomConv(keras.layers.Layer):\n",
    "    def __init__(self, dim_kernel=3, filters=8):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.dim_kernel = dim_kernel\n",
    "        self.filters = filters\n",
    "\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.w = self.add_weight(\n",
    "            shape=(self.dim_kernel, self.dim_kernel, self.filters),\n",
    "            initializer='uniform',\n",
    "            trainable=True\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        output_tensor = []\n",
    "        padded_image = tf.pad(inputs, paddings=[(0,0), (1,1), (1,1), (0,0)])\n",
    "\n",
    "        for filter in range(self.filters):\n",
    "            for i in range(28):\n",
    "                for j in range(28):\n",
    "\n",
    "                    temp_list = []\n",
    "                    for k in range(inputs.shape[-1]):\n",
    "\n",
    "                        input_tensor = padded_image[i:i+self.dim_kernel, j:j+self.dim_kernel, k]\n",
    "                        temp_list.append(self.conv(input_tensor, self.w[:,:,filter]))\n",
    "                    \n",
    "                    temp_list = tf.math.reduce_mean(temp_list)\n",
    "                    output_tensor.append(tf.keras.activations.relu(temp_list))\n",
    "        \n",
    "        output_tensor = tf.stack(output_tensor)\n",
    "        output_tensor = tf.reshape(output_tensor, shape=(-1, 28, 28, self.filters))\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " custom_conv_21 (CustomConv)  (1, 28, 28, 8)           72        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (1, 6272)                 0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (1, 10)                   62730     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,802\n",
      "Trainable params: 72\n",
      "Non-trainable params: 62,730\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.InputLayer(input_shape=(28,28,1), batch_size=batch_size),\n",
    "    CustomConv(),\n",
    "    #layers.Conv2D(16, 3, trainable=False, padding='same'),\n",
    "    #layers.Conv2D(16, 3, trainable=False, padding='same'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(10, activation='softmax', trainable=False)\n",
    "])\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.build()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images[:num_train_images]\n",
    "train_labels = train_labels[:num_train_images]\n",
    "\n",
    "x_train, x_val, y_train, y_val = prep_dataset(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train doesn't even start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantum custom conv based on the previous, the only difference is the function that outputs the feature maps, a \n",
    "convolution for the former cells and a quantum circuit for the subsequent cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(quantum_device, interface=\"tf\")\n",
    "def q_circuit(input, weights):\n",
    "            \n",
    "    features = tf.squeeze(input)\n",
    "    num_qbits = len(features)\n",
    "\n",
    "    qml.AngleEmbedding(features=features, wires=range(n_qbits), rotation='X')\n",
    "    qml.BasicEntanglerLayers(weights=weights, wires=range(n_qbits))\n",
    "            \n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_qbits)]\n",
    "\n",
    "\n",
    "class QuantumConvolution(keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, q_filters=16, dim_q_kernel=3, circuit_layers=2):\n",
    "\n",
    "        super().__init__()\n",
    "        self.dim_q_kernel = dim_q_kernel\n",
    "        self.q_filters = q_filters\n",
    "        self.circuit_layers = circuit_layers\n",
    "        self.w = self.add_weight(\n",
    "            shape = (self.circuit_layers, (self.dim_q_kernel)**2, self.q_filters),\n",
    "            initializer = 'random_normal',\n",
    "            trainable=True\n",
    "        )\n",
    "\n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.rows = input_shape[0]\n",
    "        self.cols = input_shape[1]\n",
    "        self.channels_in = input_shape[2]\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        output_tensor = []\n",
    "        padded_image = tf.pad(inputs, paddings=[(1,1), (1,1), (0,0)])\n",
    "\n",
    "        for filter in range(self.q_filters):\n",
    "            for i in range(self.rows):\n",
    "                for j in range(self.cols):\n",
    "\n",
    "                    temp_list = []\n",
    "                    for k in range(self.channels_in):\n",
    "\n",
    "                        input_tensor = padded_image[i:i+self.dim_q_kernel, j:j+self.dim_q_kernel, k]\n",
    "                        measurements = q_circuit(input_tensor, self.w[:,:,filter])\n",
    "                        measurements = tf.math.reduce_mean(measurements)\n",
    "                        temp_list.append(measurements)\n",
    "                    \n",
    "                    temp_list = tf.math.reduce_mean(temp_list)\n",
    "                    output_tensor.append(tf.keras.activations.relu(temp_list))\n",
    "        \n",
    "        output_tensor = tf.stack(output_tensor)\n",
    "        output_tensor = tf.reshape(output_tensor, shape=(self.rows, self.cols, self.q_filters))\n",
    "\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    QuantumConvolution(),\n",
    "    #layers.Conv2D(16,3, trainable=False),\n",
    "])\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.build(input_shape=(28,28,1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to put a quantum layer as a dense layer at the end of the classical model, used the pennylan tool\n",
    "for converting a quantum function to a keras layer (https://pennylane.ai/qml/demos/tutorial_qnn_module_tf.html)\n",
    "it presents a bug as it states that the weights of the quantum circuit are 'unused' as one can see\n",
    "in model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(quantum_device)\n",
    "def quantum_convolution(\n",
    "    inputs,\n",
    "    weights):\n",
    "\n",
    "    features = np.ravel(inputs)\n",
    "    qml.AngleEmbedding(features, wires=range(n_qbits), rotation='X')\n",
    "    qml.BasicEntanglerLayers(weights, wires=range(n_qbits))\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_qbits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_shapes = {\"weights\": (2, 9)}\n",
    "\n",
    "qlayer = qml.qnn.KerasLayer(quantum_convolution, weight_shapes, output_dim=n_qbits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 28, 28, 1)         10        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 1)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 1)         10        \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 1)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 7, 7, 1)           10        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 1)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    (None, 9)                 0 (unused)\n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                100       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130\n",
      "Trainable params: 0\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    layers.Conv2D(1,3, activation='relu', padding='same', trainable=False, input_shape=(28,28,1)),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(1,3, activation='relu', padding='same', trainable=False),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(1,3, activation='relu', padding='same', trainable=False),\n",
    "    layers.MaxPooling2D(),\n",
    "    qlayer,\n",
    "    layers.Dense(10, activation='softmax', trainable=False)\n",
    "])\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images[:num_train_images]\n",
    "train_labels = train_labels[:num_train_images]\n",
    "\n",
    "x_train, x_val, y_train, y_val = prep_dataset(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the 'unused' next to the quantum circuit layer in the previous model.summry() the weights seems to enter in the\n",
    "optimization routine as all the other layers are set to 'trainable = False' and the loss stil goes down "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x = x_train,\n",
    "    y = y_train,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=epochs,\n",
    "    shuffle=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f84fa9da9fc9effead0dc3a0ddec46df01cd77a4c130e3b9442917017e134d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
