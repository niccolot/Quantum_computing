{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "comp_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd()\n",
    "data_dir = os.path.join(project_dir, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PLOTTING FUNCTIONS\n",
    "\"\"\"\n",
    "\n",
    "def plot_loss_metric(loss, val_loss, metric, val_metric, metric_name='accuracy'):\n",
    "\n",
    "    epochs_range = range(len(loss))\n",
    "\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if metric_name == 'accuracy':\n",
    "        plt.plot(epochs_range, metric, label='Training Accuracy')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Accuracy')\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "    elif metric_name == 'recall':\n",
    "        plt.plot(epochs_range, metric, label='Training Recall')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Recall')\n",
    "        plt.title('Training and Validation Recall')\n",
    "    elif metric_name == 'precision':\n",
    "        plt.plot(epochs_range, metric, label='Training Precision')\n",
    "        plt.plot(epochs_range, val_metric, label='Validation Precision')\n",
    "        plt.title('Training and Validation Precision')\n",
    "    plt.legend(loc='lower right')\n",
    "    \n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 50\n",
    "learning_rate = 1e-3\n",
    "drop_rate = 0.5\n",
    "n_qbits = 9\n",
    "\n",
    "q_device = qml.device(\"default.qubit\", wires=n_qbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=data_dir,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.ToTensor(),\n",
    ")\n",
    "\n",
    "train_dl = DataLoader(training_data, batch_size=batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "quantum conv\n",
    "\"\"\"\n",
    "\n",
    "class QuantumConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        weights_tensor = torch.Tensor(self.out_channels, self.in_channels*(self.kernel_size)**2)\n",
    "        self.weights = nn.Parameter(weights_tensor)\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "\n",
    "\n",
    "    def compute_windows(self, x):\n",
    "        return nn.functional.unfold(x, self.kernel_size, padding=1)\n",
    "\n",
    "\n",
    "    @qml.qnode(q_device, interface=\"torch\")\n",
    "    def quantum_circuit(x, weights):\n",
    "\n",
    "        weights = torch.unsqueeze(weights, 0)\n",
    "        qml.AngleEmbedding(features=x, wires=range(n_qbits), rotation='X')\n",
    "        qml.BasicEntanglerLayers(weights=weights, wires=range(n_qbits))\n",
    "\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(n_qbits)]\n",
    "\n",
    "    \n",
    "    def quantum_conv(self, x, weights):\n",
    "        \n",
    "        measurements = self.quantum_circuit(x, weights)\n",
    "        return torch.mean(measurements)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        padded_input = nn.functional.pad(x, (1,1,1,1), value=0.)\n",
    "        output_tensor = torch.zeros(\n",
    "            [x.shape[0], self.out_channels, 28*28],\n",
    "            dtype = torch.float32\n",
    "        )\n",
    "        \n",
    "        windows = self.compute_windows(padded_input)\n",
    "\n",
    "        for ibatch in range(x.shape[0]):\n",
    "            for chan_out in range(self.out_channels):\n",
    "\n",
    "                for window in range(28*28):\n",
    "                    qconv = self.quantum_conv(windows[ibatch,:,window], self.weights[chan_out])\n",
    "                    output_tensor[ibatch, chan_out, window] = qconv\n",
    "\n",
    "        output_tensor = output_tensor.view(x.shape[0], self.out_channels, 28, 28)\n",
    "        \n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.myconv = QuantumConv(1,8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(28*28*8,64)\n",
    "        self.fc2 = nn.Linear(64,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        x = self.myconv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "customModel = Qnet()\n",
    "opt = torch.optim.Adam(customModel.parameters(), lr=learning_rate)\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    \n",
    "    train(train_dl, customModel, loss_func, opt)\n",
    "    test(test_dl, customModel, loss_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5f84fa9da9fc9effead0dc3a0ddec46df01cd77a4c130e3b9442917017e134d1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
